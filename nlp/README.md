# Contents
* [Overview](#overview)
* [Investigations](#investigations)
* [References](#references)

# Overview
Explore NLP using Pythong & R

# Investigations

## Topic modeling
* Approaches: LSA/LSI, pLSA/pLSI, LDA
* Tools: gensim, LDA in Spark MLlib

## Sentiment Analysis
* determine emotional status of text
* Solutions: Keyword spotting, Binary sentiment analysis
* Tools: ?

## Summarization##
* Solutions: ?
* Tools: ?

## Named Entity Recognition
* Solutions: ?
* Tools: ?

## Sequence Modeling
* Solutions: ?
* Tools: ?

## Part of Speech tagging
* Solutions: ?
* Tools: ?

## Language detection**
* Solutions: n-grams
* Tools: ?

## Topics
### TF-IDF
* Used to categorize documents
* Compute importance of terms inside documents

## Tools

* **Python:** `NLTK`, `Spacy`, `gensim` for Tokenization, word vectors, speech tagger, dependency parser
* **PySpark:** `LDA` for topic modeling
* **R:** `tm` for text mining

# References
* Wiki
* [Quora: LDA vs. pLSA ](https://www.quora.com/What-are-the-reasons-to-choose-LDA-over-pLSA-or-vice-versa)
* [Apache OpenNLP](https://opennlp.apache.org/) - Handles common NLP tasks like tokenization, segmentation, NER, part-of-speech tagging, chunking, parsing, coreference resolution
* [Stanford Core NLP](http://stanfordnlp.github.io/CoreNLP/) - Java with 3rd party Python interfaces
* [spaCy](https://spacy.io/) - Python
* [NLTK](http://www.nltk.org/)
* [Apache Tika](https://tika.apache.org/) - content analysis toolkit to extract meta-data from > 1000 file types
